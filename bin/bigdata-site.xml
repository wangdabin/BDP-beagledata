<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	 <!-- 输入压缩文件支持 
   <property>
    	<name>io.compression.codecs</name>
    	<value>org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec</value>
   </property>
   -->
   <!-- HDFS HA Start -->
	<property>
		<name>fs.default.name</name>
		<value>hdfs://bdpha</value>
	</property>

	<property>
		<name>dfs.nameservices</name>
		<value>bdpha</value>
	</property>

	<property>
		<name>dfs.federation.nameservices</name>
		<value>bdpha</value>
	</property>

	<property>
		<name>dfs.ha.namenodes.bdpha</name>
		<value>nn1,nn2</value>
	</property>

	<property>
		<name>dfs.namenode.rpc-address.bdpha.nn1</name>
		<value>192.168.32.18:8020</value>
	</property>

	<property>
		<name>dfs.namenode.rpc-address.bdpha.nn2</name>
		<value>192.168.32.19:8020</value>
	</property>
	<property>
	   <name>dfs.client.failover.proxy.provider.bdpha</name> 
	   <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
	</property>
	
	 <!-- HDFS HA End -->
	
	<property>
		<name>mapred.job.tracker</name>
		<value>master:9001</value>
	</property>
	<property>
		<name>mapreduce.jobtracker.address</name>
		<value>master:9001</value>
	</property>
   <property>
		<name>hbase.zookeeper.quorum</name>
		<value>master1,master,node1</value>
	</property>
	<property>
		<name>hbase.zookeeper.property.clientPort</name>
		<value>2181</value>
	</property>
	<property>
		<name>mapred.reduce.tasks</name>
		<value>5</value>
	</property>
	<property>
		<name>fs.jmx.host</name>
		<value>192.168.32.18:50070</value>
	</property>
	<property>
		<name>dfs.replication</name>
		<value>3</value>
	</property>
<!--  
	<property>
	    <name>mapred.compress.map.output</name>
	    <value>true</value>
   </property>
 
    <property>
    	<name>mapred.map.output.compression.codec</name>
    	<value>org.apache.hadoop.io.compress.GzipCodec</value>
    </property>
-->
	<!-- 
	<property>
		<name>mapreduce.framework.name</name>
		<value>classic</value>
	</property>
 
   <property>
    	<name>mapred.output.compress</name>
    	<value>true</value>
 	</property>

  	<property>
   	 	<name>mapred.output.compression.codec</name>
    	<value>org.apache.hadoop.io.compress.SnappyCodec</value>
  	</property>
-->
	<property>
		<name>compress.max.thread</name>
		<value>1</value>
	</property>
		 
	<property>
		<name>init.region.startkey</name>
		<value>0|http://0</value>
	</property>

	<property>
		<name>init.region.endkey</name>
		<value>0|http://~~~~~~~~~</value>
	</property>
	<property>
		<name>importer.max.thread</name>
		<value>20</value>
	</property>
	<property>
		<name>hbase.table.ttl</name>
		<value>10</value>
	</property>
	<property>
		<name>hbase.table.family</name>
		<value>I</value>
	</property>
	<property>
		<name>hbase.table.qualifier</name>
		<value>Q</value>
	</property>
	<property>
		<name>hbase.table.numregions</name>
		<value>99</value>
	</property>
	<property>
		<name>table.is.existed.drop</name>
		<value>true</value>
	</property>	
	<property>
		<name>mobilephone.table.name</name>
		<value>phone</value>
	</property>
	<property>
		<name>log.property.path</name>
		<value>log.property</value>
	</property>
	<property>
		<name>hbase.table.classifier.name</name>
		<value>classification</value>
	</property>
	<property>
		<name>hbase.table.classifier.family.name</name>
		<value>I</value>
	</property>
	<property>
		<name>hbase.table.classifier.qualifier.name</name>
		<value>Q</value>
	</property>
	<property>
		<name>hbase.table.classifer.statistic.name</name>
		<value>statistic</value>
	</property>
	<property>
		<name>hbase.table.classifer.statistic.family.name</name>
		<value>I</value>
	</property>	
	<property>
		<name>hbase.table.classifer.statistic.qualifier.name</name>
		<value>Q</value>
	</property>		
	<property>
		<name>auto.send.message.to.mq</name>
		<value>false</value>
	</property>

	<property>
		<name>mr.job.monitor.enable</name>
		<value>true</value>
	</property>	
	
	<!--  -->
	<property>
		<name>cluster.monitor.table</name>
		<value>CLUSTER_ALERT_T</value>
	</property>	
	
	<property>
		<name>ssh.pem.path</name>
		<value>/home/hadoop/.ssh/id_rsa</value>
	</property>	
	
	<property>
		<name>sshuser</name>
		<value>hadoop</value>
	</property>	
	<property>
		<name>sshpassword</name>
		<value>123456</value>
	</property>	
	<property>
		<name>hadoop.path</name>
		<value>/opt/hadoop/bin</value>
	</property>	
	<property>
		<name>hbase.path</name>
		<value>/opt/hbase/bin</value>
	</property>	
	<property>
		<name>zookeeper.path</name>
		<value>/opt/zookeeper/bin</value>
	</property>	
	<property>
		<name>com.skycloud.regionserver.restart</name>
		<value>false</value>
	</property>

	<property>
		<name>com.skycloud.zookeeper.restart</name>
		<value>true</value>
	</property>
	
	<property>
		<name>com.skycloud.datanode.restart</name>
		<value>false</value>
	</property>
	
	<property>
		<name>com.skycloud.jobtracker.restart</name>
		<value>false</value>
	</property>
	
	<property>
		<name>com.skycloud.tasktracker.restart</name>
		<value>false</value>
	</property>
	<property>
		<name>com.skycloud.namenode.restart</name>
		<value>false</value>
	</property>
	<property>
		<name>com.skycloud.journalnode.restart</name>
		<value>false</value>
	</property>
	<property>
   	   <name>dfs.namenode.shared.edits.dir</name>
       <value>qjournal://master:8485/bdpha</value>
  </property>
</configuration>